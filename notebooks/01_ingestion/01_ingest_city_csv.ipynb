{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d66fc4c-79f9-498b-b8db-624b1a1cf3f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../00_config/01_urls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9865569f-081c-4cae-ac0a-ad07a46d5665",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../00_config/00_adls_config\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "393c444a-a54d-486d-8812-df5b324e750f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col, regexp_replace, trim\n",
    "from datetime import datetime\n",
    "df = spark.read.csv(\n",
    "    f\"{BRONZE_LAYER_PATH}city_data/city.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    ")\n",
    "\n",
    "df_cleaned = df \\\n",
    "    .withColumnRenamed(\"lat\", \"latitude\") \\\n",
    "    .withColumnRenamed(\"lon\", \"longitude\") \\\n",
    "    .withColumn(\"state\",when(col(\"state\").isNull(), trim(regexp_replace(col(\"city\"), r\"(?i)^thành\\s+ph[ốo]\\s*\", \"\"))).otherwise(trim(regexp_replace(col(\"state\"),\"Province\",\"\"))))\\\n",
    "    .select(\"country\",\"state\",\"latitude\",\"longitude\")\n",
    "\n",
    "current_date_path = datetime.now().strftime(\"%Y/%m/%d\")\n",
    "silver_output_path=f\"{SILVER_LAYER_PATH}city_data_cleaned/dt={current_date_path}/\"\n",
    "df_cleaned.write.format(\"delta\").mode(\"append\").save(silver_output_path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_ingest_city_csv",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
